\documentclass{amsart}
\usepackage{graphicx}
\graphicspath{{./}}
\usepackage{hyperref}
\usepackage{csvsimple}
\usepackage{longtable}
\usepackage{lscape}
\usepackage{epigraph}
\title{All Noise in Nature is Barndorff-Nielsen}
\author{Zulfikar Moinuddin Ahmed}
\date{\today}
\begin{document}
\maketitle

\section{Context}

Years ago, in the early 1700s, De Moivre and others had discovered that binomial distributions approximate the normal distribution.  Yes, it existed before Gauss wrote a phenomenal paper that attached his name to them, but people used normal Gaussians before Gauss.  But this sort of thing, binomial leading to normal distribution, these are toy models.  Nature never actually respected the idea, and rejected Gaussian noise all over Science.  In fact noise is almost never Gaussian.  

It has been my conviction for many years now that if the noise is from Nature, it is Barndorff-Nielsen, Generalised Hyperbolic Distribution.  This is Nature's choice of noise.  Nature produces no other sorts of Noise at all.  Nature produces Barndorff-Nielsen Generalised Hyperbolic Distribution Noise.

If your noise was not artificially constructed, then it is Barndorff-Nielsen Generalised Hyperbolic.  Not an approximation.  It's Nature's noise these precise analytic parametric distributions.  I hold the conviction that unless something produces multi-modal distributions or some other thing, Barndorff-Nielsen GHD will fit it.  Nature does not know how to produce other sorts of Noise.

To be clear, sometimes rarely, noise will be Gaussian. How rare?  My estimate from considering above 3000+ time series gave the estimate 7\% of the times or so.  It's not significant.  Barndorff-Nielsen GHD will fit noise almost 100\% of the time, and that is real progress in Science.  

\section{In Social Sciences}

My work with World Values Survey does not even have significant examples of distributions that are not covered by Barndorff-Nielsen GHD.  These are infinitely divisible, which amounts to saying that they occur as $X_1+\dots+X_p$ for arbitrary $p$ and some iid $X_j$.  In other words, they occur just like Gaussians but they are more precise and flexible in fitting all the noise you can throw at them.  So they will clean up Gaussians.  Gaussians are great learning tools and also useful for theory, but yous should abandon them permanently from Science, and {\em only then} can you get a real feel for signal-to-noise.  You've been lost and confused and pretended that signals of form $ S_m = S + \epsilon$ with $\epsilon \sim GHD(\theta)$ were $S_m + S' + \eta$ with $\eta \sim N(a,b)$.  That's so sad and horrible.  That is so sad because you were fitting to all manner of noise, getting all sample size computations wrong, and were making all sorts of horrible inference errors, and I don't want to burst your bubble, but I am in the know that the laughter of the gods were resounding.  You didn't hear it I suppose.  Well, that's good. It's quite annoying, the laughter of the gods.  They do laugh at me too, so don't feel too bad.  

\end{document}