\documentclass{amsart}
\usepackage{graphicx}
\graphicspath{{./}}
\usepackage{hyperref}
\usepackage{csvsimple}
\usepackage{longtable}
\usepackage{epigraph}
\title{Zulf's Universal Markov Chain Hypothesis for Full Spectrum of Moral Character in Humans}
\author{Zulfikar Moinuddin Ahmed}
\date{\today}
\begin{document}
\maketitle

\section{Transition Matrix}

I could establish invariance of joint frequency matrix for moral values Q177--Q195.  The topics are quite varied, and yet there is an invariance for the pairwise frequency.   The mean matrix is symmetric but looks quite non-trivial.

\begin{verbatim}
> matrix(y,nrow=3,ncol=3)
          [,1]       [,2]       [,3]
[1,] 0.1598992 0.03940620 0.09441660
[2,] 0.0394062 0.05896421 0.07437498
[3,] 0.0944166 0.07437498 0.36474105
\end{verbatim}
Whenever one sees this situation with some mathematical background, one considers an infinite sequence of moral values $Y= (Y_1,Y_2,\dots)$ with $Y_j \in \{1,2,3\}$ with the transition density given by the symmetric matrix.  

In other words, if we ignore the identity of the moral value, such as "Is it justifiable to steal" or "Is it justifiable to push an old grandmother over the Golden Gate Bridge when no one is looking" etc. we have empirically discovered a {\em homogeneity} for moral values.  

So we put aside our prejudices about morals, and consider the situation that moral values in a person is determined by some cascade that is stochastically generated.  We won't worry about the ordering of the cascade.  Instead we'll just assume that they are the realisation of a Markov chain with transition matrix $P$.

Does this actually make any sense?  That will be the subject of some of my work in the near future.

\section{Universal Markov Generation of Moral Character Hypothesis May 4 2021}

The simplest version of my hypothesis is that there exists a $10\times 10$ symmetric transition density such that the observed variety of Human Moral Character are simply realisations of Markov Chains generated by the transition matrix.

I further hypothesize that the exponential distributions observed are a consequence of the hypothetical generator of Human Moral Character in large sample.

\section{Simulation Exercise Ideas}

Let us consider the following problem.  Suppose the entire human race moral character is, counterfactually, fully characterised by the following situation.

All moral character s are given by $M$ measurements that are realisations of discrete random variables $Y = (Y_1, \dots, Y_M)$.  Let us refer to the particular component $Y_j$ as answer to $Q_j$.  For a large number $N$ of people, we have measurements $y^1_j,\dots, y^N_j$.  Then when we tally it up we find a distribution on $I=[1,\dots, 10]$ and then find they are approximately exponentially distributed.  Furthermore, we assume pairwise, the joint probability matrix is constant $P$.

This situation is approximately true from empirical data.  

Our {\em theoretical problem} is to characterise the $P$ for which, given exponential distribution known for $Q_1$ the whole human race distributions, for $Q_2, \dots, Q_M$ are all fully determined by $P$ alone.

\section{Conjecture for Form of $P$}

We consider the following type of matrix.  Let's take $\lambda>0$.  Then we consider the procedure of producing a symmetric matrix from this.

Put some number $p_{11}>0$ on the top left.  Let us put down 
\[
p_{k1} = e^{-\lambda k}p_{11}
\]
Then
\[
p_{k\ell} = e^{-\lambda(k+\ell)}p_{11}
\]
Then symmetrise and normalise to row sum 1.

This type of Markov transition matrix ought to reproduce exponential distributions for the distributions of $Y_2,\dots, Y_M$.  

\begin{verbatim}
# Reproduce M=20 Exponentials
# for entire human race

lambda <- 0.52
p11 <- 0.6
P <- matrix(0,nrow = 10, ncol=10)
P[1,1] = p11
for (k in 2:10){
  for (r in 1:k){
    P[k,r] <- exp(-lambda*(k+r))*p11
    P[r,k] <- P[k,r]
  }
}
for ( r in 1:10){
  P[r,]<-P[r,]/sum(P[r,])
}

Y1 <- floor(rexp(1000,rate=0.5))+1
Y1[Y1>10]<-10

library(markovchain)
mcVals = new("markovchain", states = as.character(seq(1,10)),
            transitionMatrix = P,          
            name = "Vals")

y1=Y1
all.Y<-matrix(0,nrow=1000,ncol=20)
all.Y[,1]<-Y1
for (kk in 1:1000) {
  outs <- rmarkovchain(n = 19, object = mcVals, what = "list")
  all.Y[kk,2:20]<-outs  
}

get.curve<-function(kk){
  Z<-table(all.Y[,kk])
  v<-rep(0,10)
  for (r in 1:10){
    v[r]<-Z[as.character(r)]
  }
  v<-v/sum(v)
  v
}
for (r in 2:10){
  a<-summary(lm(log(get.curve(r))~t10))$r.squared
  print(a)
}

[1] 0.9600893
[1] 0.9406608
[1] 0.9698023
[1] 0.9535682
[1] 0.9734414
[1] 0.9583213
[1] 0.9753026
[1] 0.9800525
[1] 0.97398
\end{verbatim}

The above code allows us to see that the scheme we have will produce exponential variables in the distribution from markov chains.

This is the simple toy model for Human Nature Moral Values.  In the future we need to carefully modify this simple model and calibrate to measurements from Nature and determine a single $P_{moral}$ that can serve as the set of parameters for all human moral character.

\section{Optimisation Issues}

I will consider the straightforward optimisation problem of fitting 55 parameters of $10 \times 10$ matrix $P$.  The objective is 
\[
A(P) = \sum_{q \in Q} \| I(q) - T(mc(Y_1, P, q)) \|_2
\]
The notation $mc(Y_0,P, k)$ stands for $k$-th step of Markov Chain simulation starting with $Y_0$ as initial value.

Fixing 10 values for, say, $I(177)$ we will have characterised all moral character of humanity in 65 parameters.

This is a feasible goal because in actuality we have 180 measurements from 18 questions.  This is beautiful science reducing 180 to 65 parameters.  

\section{Speculations Regarding meaning of 65 parameters}

Suppose we find that we have a great fit of all the data with 65 parameters.

Our interpretation is that each of us has inner psychological or physiological that express themselves in answering World Values Survey.  At the moment we don't care what they are; although we are not Behaviorists like B. F. Skinner.  However, we can generate answers to 180 variables and this is our proxy of all moral variables.

\section{Optimisation Code}

\begin{verbatim}
# Fit P to distributions to Q177-Q195 in WVS 7

transitionMatrixFromPars<-function(x){
  P<-matrix(0,nrow=10,ncol=10)
  P[1,1]<-x[1]
  P[1:2,2]<-x[2:3]
  P[1:3,3]<-x[4:6]
  P[1:4,4]<-x[7:10]
  P[1:5,5]<-x[11:15]
  P[1:6,6]<-x[16:21]
  P[1:7,7]<-x[22:28]
  P[1:8,8]<-x[29:36]
  P[1:9,9]<-x[37:45]
  P[1:10,9]<-x[46:55]
  #symmetrize
  for (k in 2:10){
    P[k,1:k]<-P[1:k,k]
  }
  for (k in 1:10){
    P[k,]<-nrm(P[k,])
  }
  P
}

parsFromTransitionMatrix<-function(P){
  x<-c()
  for (k in 1:10){
    x<-append(x, P[1,1:k])
  }
  x
}

# We let x be the parameters of the subdiagonal
# of P in form appropriate for an optimiser
moral_markov_obj<-function( x ){
  
  P <- transitionMatrixFromPars( x )
  states <- as.character(1:10)
  mcVals = new("markovchain", 
               states = states,
               transitionMatrix = P,          
               name = "Vals")
  
  Imtx <- matrix( 0, nrow=18,ncol=10)
  Jmtx <- matrix( 0, nrow=18, ncol=10)
  I1<-nrm(table(polv[,"Q177"]))
  Imtx[1,] <- I1
  
  Y1<-sample(1:10,1000,replace=TRUE,prob=I1)

  all.Y<-matrix(0,nrow=1000,ncol=18)
  all.Y[,1]<-Y1
  for (kk in 1:1000) {
    outs <- rmarkovchain(n = 17, object = mcVals, what = "list")
    all.Y[kk,2:18]<-outs  
  }

  for ( r in 2:18 ){
    Imtx[r,]<-nrm(table(polv[,vars[r]]))
    Jmtx[r,]<-nrm(table(all.Y[,r]))
  }
  
  l2.dist <- 0
  for (r in 1:18){
    d <- norm( abs(Imtx[,r] - Jmtx[,r] ), p="2")
    l2.dist <- l2.dist + d^2
  }
  l2.dist<-sqrt(l2.dist)
  l2.dist
}



get.curve<-function(kk){
  Z<-table(all.Y[,kk])
  v<-rep(0,10)
  for (r in 1:10){
    v[r]<-Z[as.character(r)]
  }
  v<-v/sum(v)
  v
}
for (r in 2:10){
  a<-summary(lm(log(get.curve(r))~t10))$r.squared
  print(a)
}

library(nloptr)
# Get an init value
lambda <- 0.52
p11 <- 0.6
P <- matrix(0,nrow = 10, ncol=10)
P[1,1] = p11
for (k in 2:10){
  for (r in 1:k){
    P[k,r] <- exp(-lambda*(k+r))*p11
    P[r,k] <- P[k,r]
  }
}
for ( r in 1:10){
  P[r,]<-P[r,]/sum(P[r,])
}
P0<-P

x0<-parsFromTransitionMatrix(P0)
xlen <- length(x0)
l0 <- rep(0,xlen)
u0 <- rep(1,xlen)

eval_g0<-function( x ){
  P1<-transitionMatrixFromPars(x)
  out<-0
  for (k in 1:10){
    out <- out + (sum(P1[k,]))^2-1.0
  }
  out
}

# Solve using NLOPT_LN_COBYLA without gradient information
res1 <- nloptr( x0=x0,
                eval_f=moral_markov_obj,
                lb = l0,
                ub = u0,
                eval_g_ineq = eval_g0,
                opts = list("algorithm"="NLOPT_LN_COBYLA",
                            "xtol_rel"=1.0e-8))
print( res1 )
\end{verbatim}



\end{document}